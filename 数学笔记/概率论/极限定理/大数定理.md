### 1.切比雪夫大数定理(弱)
如果 $\xi_1,\xi_2,\cdots ,\xi_n$ 两两不相关的随机变量,且他们的方差有界 $|D[\xi_i]| \leq |C_i| < \infty$ ,则有:

$$\begin{align}
    \lim_{n\rightarrow +\infty} P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}E[\sum_{i=1}^n\xi_i]|\leq \epsilon \} = 1
\end{align}$$

由于独立一定能得到不相关,则说明不相关 $n$ 次实验


证明:

$$\begin{align}
    P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}E[\sum_{i=1}^n\xi_i]|\leq \epsilon \} = 1 - P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}E[\sum_{i=1}^n\xi_i]|> \epsilon \}
\end{align}$$


对于:

$$\begin{align}
    P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}E[\sum_{i=1}^n\xi_i]|> \epsilon \} = P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - E[\frac{1}{n}\sum_{i=1}^n\xi_i]|> \epsilon \}
\end{align}$$

把 $\xi = \frac{1}{n}\sum_{i = 1}^{n}\xi_i$ ,利用切比雪夫不等式有:

$$\begin{align}
P\{|\xi  - E[\xi]|>\epsilon \} \leq \frac{D[\xi
]}{\epsilon^2}
\end{align}$$

取 $C = \max\{D[\xi_1],D[\xi_2],\cdots D[\xi_n]\}$ 故：

$$\begin{align}
    P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - E[\frac{1}{n}\sum_{i=1}^n\xi_i]|> \epsilon \} \leq \frac{D[\frac{1}{n}\sum^{n}_{i=1}\xi_i]}{\epsilon^2} = \frac{D[\sum_{i=1}^n\xi_i]}{n^2\epsilon^2} \leq \frac{\sum
    _{i=1}^nC_i}{n^2\epsilon^2} \leq \frac{C}{n\epsilon^2}
\end{align}$$

那么有:

$$\begin{align}
    0\leq P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - E[\frac{1}{n}\sum_{i=1}^n\xi_i]|> \epsilon \} \leq \frac{C}{n\epsilon^2}
\end{align}$$

两边对 $n$ 取无穷,利用夹逼准则有:

$$\begin{align}
    \lim_{n\rightarrow +\infty} P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - E[\frac{1}{n}\sum_{i=1}^n\xi_i]|> \epsilon \} = 0
\end{align}$$

那么对式 $(2)$ 有:

$$\begin{align}
    \lim_{n\rightarrow +\infty} P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}E[\sum_{i=1}^n\xi_i]|\leq \epsilon \} = 1
\end{align}$$

证毕.

### 2.马尔可夫大数定理
对于随机变量序列 $\{\xi_n \}$ ,如果有:

$$\begin{align}
    \frac{1}{n^2}D[\sum_{i=1}^{n}\xi_i^2] \rightarrow 0
\end{align}$$

则对于任意的 $\epsilon>0$:

$$\begin{align}
    \lim_{n\rightarrow +\infty} P\{|\frac{1}{n}\sum_{i=1}^n\xi_i - \frac{1}{n}\sum_{i=1}^nE[\xi_i]|<\epsilon \} = 1
\end{align}$$

马尔可夫的大数定理已经对独立性和不相关性,是否同分布没有任何要求.只需要方差存在即可.

### 3.辛钦大数定理(强).
如果 $\xi_1,\xi_2,\cdots ,\xi_n$ 独立同分布的随机变量,且他们的期望一致

$$\begin{align}
    E[\xi_i] = a,i=1,2\cdots n
\end{align}$$

则对于任意 $\epsilon >0$ ,有

$$\begin{align}
    \lim_{n\rightarrow +\infty} P\{|\frac{1}{n}\sum_{i=1}^{n}\xi_i - a|<\epsilon \} = 1
\end{align}$$

把上式通常写为:

$$\begin{align}
    \lim_{n\rightarrow +\infty} \frac{1}{n} \sum_{i=1}^n\xi_i = a \\
    \eta = \frac{1}{n} \sum_{i=1}^n \xi_i \rightarrow a (n\rightarrow +\infty)
\end{align}$$

称 $\displaystyle \frac{1}{n} \sum_{i=1}^n\xi_i $ 依概率收敛于 $a$ .

### 4.总结
#### 4.1切比雪夫与辛钦
相同点
* 都是收敛于均值
* 都要求随机变量的期望一致.
不同点
* 切比雪夫随机变量可以不同分布,不独立,只要不相关,期望和方差一致并且有界即可;辛钦大数定理则是要求随机变量同分布并且相互独立,而且要期望一致.

### 5.例题
设 $X_1,X_2,\cdots X_n$ 都是独立同分布的随机变量,且 $E[X_i] = 0$ ,求

$$\begin{align}
    \lim_{n\rightarrow+\infty}P\{\sum_{i=1}^nX_i <n\}
\end{align}$$

解:
$X_1,X_2,\cdots X_n$ 都是独立同分布且 $E[X_i] = 0$ ,由辛钦大数定理有:对于任意 $\epsilon >0$

$$\begin{align}
    \lim_{n\rightarrow+\infty}P\{|\frac{1}{n}\sum_{i=1}^nX_i  - 0|<\epsilon \} = 1 \rightarrow \lim_{n\rightarrow+\infty}P\{-\epsilon<\frac{1}{n}\sum_{i=1}^nX_i  <\epsilon \} = 1
\end{align}$$

取 $\epsilon = 1$ ,得

$$\begin{align}
\lim_{n\rightarrow+\infty}P\{-1<\frac{1}{n}\sum_{i=1}^nX_i  <1 \} = 1
\end{align}$$

因为

$$\begin{align}
    \lim_{n\rightarrow+\infty}P\{\sum_{i=1}^nX_i <n\} = \lim_{n\rightarrow+\infty}P\{\frac{1}{n}\sum_{i=1}^nX_i <1\}
\end{align}$$

由于:

$$\begin{align}
    P\{-1<\frac{1}{n}\sum_{i=1}^nX_i  <1 \}\leq P\{\frac{1}{n}\sum_{i=1}^nX_i <1\} \leq 1
\end{align}$$

两边取极限,由夹逼定理有:

$$\begin{align}
    \lim_{n\rightarrow+\infty}P\{\sum_{i=1}^nX_i <n\} = 1
\end{align}$$